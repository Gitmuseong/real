import pandas as pd
import joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("Mineral_Dataset_Supplementary_Info.csv")

# 2. ì‚¬ìš©í•  íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì„¤ì •
features = [
    "density_Average", "atomicweight_Average", "val_e_Average",
    "ionenergy_Average", "el_neg_chi_Average"
]
target = "Hardness"

# 3. ê²°ì¸¡ì¹˜ ì œê±°
df = df[features + [target]].dropna()

# 4. ì…ë ¥(X), íƒ€ê²Ÿ(y) ì„¤ì •
X = df[features]
y = df[target]

# 5. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì…‹ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. ëª¨ë¸ í•™ìŠµ
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 7. ì„±ëŠ¥ í‰ê°€
y_pred = model.predict(X_test)
print("ğŸ” RMSE:", mean_squared_error(y_test, y_pred, squared=False))
print("ğŸ“ˆ RÂ² score:", r2_score(y_test, y_pred))

# 8. ëª¨ë¸ ì €ì¥
joblib.dump(model, "model.pkl")
print("âœ… model.pkl íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
